{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Solutions\n",
        "\n",
        "\n",
        "## 1. ANN"
      ],
      "metadata": {
        "id": "C5SO8BNp1Nft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have created DataLoaders we now can iterate over them.\n",
        "In the the next cell, there is the loop for iterating over `trainset` and inspect it. Do the same with `testset`!"
      ],
      "metadata": {
        "id": "VyjGfNXX7psh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for data in testset:\n",
        "    batch_of_images = data[0]\n",
        "    print(batch_of_images.size())\n",
        "    batch_of_labels = data[1]\n",
        "    print(batch_of_labels.size())\n",
        "\n",
        "    fig = plt.figure()\n",
        "    fig.set_size_inches(18.5, 10.5, forward=True)\n",
        "    for i, (image, label) in enumerate(zip(batch_of_images,batch_of_labels)):\n",
        "        plt.subplot(2,5,i+1)\n",
        "        plt.imshow(image.view(28,28), cmap='gray', interpolation='none')\n",
        "        plt.title(f\"Ground Truth: {label}\")\n",
        "    fig\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "9RhkeQEy1Uio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now verify the Network with one of data from our dataset. \n",
        "Hint: Take a batch from out `trainset` using `next(iter(trainset))`."
      ],
      "metadata": {
        "id": "OGHV5wjK7wQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = next(iter(trainset))[0][0]\n",
        "print('Input:')\n",
        "plt.imshow(X.view(28,28))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "X = X.view(-1,28*28) # neural network wants this to be flattened\n",
        "output = net(X)\n",
        "print(f'Output: {output}')"
      ],
      "metadata": {
        "id": "rCAcnTGT4rG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WSmwKjOV72iX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jGD5SfY1I4k"
      },
      "outputs": [],
      "source": [
        "NUMBER_OF_HIDDEN_LAYERS = 5\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 64)\n",
        "        self.hidden_layers = nn.Sequential()\n",
        "        #### YOUR CODE HERE\n",
        "        for i in range(NUMBER_OF_HIDDEN_LAYERS):\n",
        "            self.hidden_layers.append(nn.Linear(64, 64))\n",
        "        self.fc_n = nn.Linear(64, 10) \n",
        "\n",
        "    # passing our data through the layers + activations\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        #### YOUR CODE HERE\n",
        "        for hl in self.hidden_layers:\n",
        "            x = F.relu(hl(x))\n",
        "        x = self.fc_n(x)\n",
        "        return F.log_softmax(x, dim=1) \n",
        "\n",
        "net = Net()\n",
        "print(net)\n",
        "\n",
        "\n",
        "X = torch.randn((28,28)) # create random 28x28 image\n",
        "print('Input:')\n",
        "plt.imshow(X.view(28,28))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "X = X.view(-1,28*28) # neural network wants this to be flattened\n",
        "output = net(X)\n",
        "print(f'Output: {output}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Autoencoders"
      ],
      "metadata": {
        "id": "rYUVKawa1Nie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the architecture of the Autoencoder by adding `nn.BatchNorm1d(out)` layer after each Linear layer, where `out` parameter should be equal the size of output of previous Linear layer. "
      ],
      "metadata": {
        "id": "DY6ABFGuDH2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Role of encoder: repeatedly reduce the size\n",
        "        # N - batch size\n",
        "        # input dimensions: 28x28 = 784\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 128), # (N, 784) -> (N, 128)\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 12),\n",
        "            nn.BatchNorm1d(12),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(12, 3) # -> N, 3\n",
        "        )\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(3, 12),\n",
        "            nn.BatchNorm1d(12),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(12, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 28 * 28),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded"
      ],
      "metadata": {
        "id": "-f5oZ-4DDG8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly to the example with Linear Autoencoder - add some Normalization layers. REMARK - use `nn.BatchNorm2d(out)` after each Conv2d or Conv2dTranspose layer."
      ],
      "metadata": {
        "id": "vNlxOgR-DIpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()        \n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=2, padding=1), # -> N, 16, 14, 14\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=1), # -> N, 32, 7, 7\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 7, stride=1, padding=0), # -> N, 64, 1, 1\n",
        "        )\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 7, stride=1, padding=0), #  -> N, 32, 7, 7\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), # -> N, 16, 14, 14\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1), # -> N, 1, 28, 28 \n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n"
      ],
      "metadata": {
        "id": "VuX04Yf3DJDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to design the Autoencoder that will be able to process our dataset with Photons. The rest (training loop, loss, optimizers) are already coded in next cells. Your role is to put layers into the encoder and decoder!\n"
      ],
      "metadata": {
        "id": "CumhDFnmQOsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder_Linear(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()        \n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(6, 6), \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(6, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(5, 3),\n",
        "        )\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(3, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(5, 6),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(6, 6)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded, encoded"
      ],
      "metadata": {
        "id": "BliltEbOQO-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. GANs\n"
      ],
      "metadata": {
        "id": "975Zod7Z3HLi"
      }
    }
  ]
}